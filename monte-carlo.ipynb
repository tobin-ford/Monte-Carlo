{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import credentials # Api key is stored in this file, remove to avoid errors if you clone from github\n",
    "\n",
    "import pvdeg\n",
    "import pvlib\n",
    "from numba import njit, jit, vectorize\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.linalg import cholesky\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get weather data and metadata for a desired location (latitude and logitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pvlib\\iotools\\psm3.py:183: pvlibDeprecationWarning: The ``get_psm3`` function will default to leap_day=True starting in pvlib 0.11.0. Specify leap_day=True to enable this behavior now, or specify leap_day=False to hide this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# change to desired values (currently Miami)\n",
    "latitude = 25.783388\n",
    "longitude = -80.189029\n",
    "\n",
    "API_KEY = credentials.API_KEY # my personal NREL api key\n",
    "email ='tobin.ford@nrel.gov' # replace these values with your appropriate information and remove and comment out first line of first block (import credentials)\n",
    "\n",
    "# reads NSRDB data \n",
    "weather_df, meta = pvlib.iotools.get_psm3(latitude, longitude, API_KEY, email, names='2019', map_variables=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User has 3 parameters for initial implementation: See Kempe's \"Deg Miami\" tab in excel<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "activation energy, Ea <br>\n",
    "irradiance relation, x<br>\n",
    "ln(R0)<br>\n",
    "\n",
    "|           |   Ea   |   x   | ln(R0) |\n",
    "|:---------:|:-----:|:----:|:-------:|\n",
    "|   **Ea**  |   1   |   a  |   b     |\n",
    "|   **x**   |   a   |   1  |   c     |\n",
    "| **ln(R0)**|   b   |   c  |   1     |\n",
    "\n",
    "Notice symmetry across diagonal <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER ENTERED VALUES\n",
    "# Correlation Coefficients\n",
    "Ea_X = 0.0269\n",
    "Ea_lnR0 = -0.9995 \n",
    "X_lnR0 = -0.0400\n",
    "\n",
    "# Activation Energy\n",
    "mean_Ea = 62.08 # average\n",
    "sd_Ea = 7.3858 # standard deviation\n",
    "\n",
    "# Irradiance relation\n",
    "mean_X = 0.0341 # average\n",
    "sd_X = 0.0992757 # standard deviation\n",
    "\n",
    "# ln(R0)\n",
    "mean_lnR0 = 13.7223084 \n",
    "sd_lnR0 = 2.47334772\n",
    "\n",
    "# number of iterations\n",
    "n = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice symmetry of matrix\n",
    "A = np.array([[1,   Ea_X,   Ea_lnR0],\n",
    "              [Ea_X,    1,   X_lnR0],\n",
    "              [Ea_lnR0, X_lnR0,   1]])\n",
    "\n",
    "# conceptually similar to the square root of a matrix\n",
    "A_decomp = cholesky(A, lower=True) \n",
    "\n",
    "# originally attempting to get a standard distribution based each parameter's mean and standard deviation for n points\n",
    "# now: creates random distribution with mean = 0 and std = 1 for n points\n",
    "ea = np.random.normal(loc=0, scale=1, size=n)\n",
    "x = np.random.normal(loc=0, scale=1, size=n)\n",
    "lnR0 = np.random.normal(loc=0, scale=1, size=n)\n",
    "\n",
    "\n",
    "# create a numPy array to use in operations later\n",
    "# somewhat misleadingly named a matrix instead of an array\n",
    "# transpose built in so I don't have to do it with another function\n",
    "samples_matrix = np.array([ea, x, lnR0])\n",
    "\n",
    "# I kind of hate this \n",
    "data = {\n",
    "    'ea': ea,\n",
    "    'x': x,\n",
    "    'lnR0': lnR0\n",
    "}\n",
    "uncorrelated_df = pd.DataFrame(data) # not sure if I am actually using this for anything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlated stats pre-input to function using MonteCarloEaLnRoX\n",
    "correlated_samples = np.matmul(A_decomp, samples_matrix)\n",
    "\n",
    "#correlated_df = pd.DataFrame(correlated_samples.T, columns=['ea', 'x', 'lnR0']) # dont think this even gets used\n",
    "\n",
    "sol_pos = pvdeg.spectral.solar_position(weather_df, meta)\n",
    "poa_irradiance = pvdeg.spectral.poa_irradiance(weather_df, meta)\n",
    "temp_mod = pvdeg.temperature.module(weather_df=weather_df, meta=meta, poa=poa_irradiance, conf='open_rack_glass_polymer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEa_New = sd_Ea * ea.std() + mean_Ea\\nlnR0_New = sd_lnR0 * lnR0.std() + mean_lnR0\\nx_NEW = sd_X * x.std() + mean_X\\n# visualize\\nprint(Ea_New)\\nprint(lnR0_New)\\nprint(x_NEW)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "general form taken to update our plain distrubution values with means and stdevs to make them meaningful \n",
    "Ea_New = sd_Ea * ea.std() + mean_Ea\n",
    "lnR0_New = sd_lnR0 * lnR0.std() + mean_lnR0\n",
    "x_NEW = sd_X * x.std() + mean_X\n",
    "# visualize\n",
    "print(Ea_New)\n",
    "print(lnR0_New)\n",
    "print(x_NEW)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.matrix(np.matmul(A_decomp, samples_matrix))\n",
    "sd_mat = np.matrix([sd_Ea, sd_X, sd_lnR0]) \n",
    "\n",
    "sd_mat_transpose = np.transpose(sd_mat)\n",
    "result = np.multiply(temp, sd_mat_transpose) + np.transpose(np.matrix([mean_Ea, mean_X, mean_lnR0]))\n",
    "\n",
    "correlated_df = pd.DataFrame(np.transpose(result), columns=['ea', 'x', 'lnR0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.993789686427405\n",
      "7.356733550925379\n",
      "\n",
      "0.03310121360987671\n",
      "0.09894135533476106\n",
      "\n",
      "13.751653603874153\n",
      "2.4635444502406028\n",
      "\n",
      "EA_X: [[1.         0.02783183]\n",
      " [0.02783183 1.        ]]\n",
      "Ea_lnR0: [[ 1.         -0.99949478]\n",
      " [-0.99949478  1.        ]]\n",
      "X_lnR0: [[ 1.         -0.04120082]\n",
      " [-0.04120082  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# dummy check for mean and standard deviation\n",
    "print(result[0].mean())\n",
    "print(result[0].std())\n",
    "print()\n",
    "print(result[1].mean())\n",
    "print(result[1].std())\n",
    "print()\n",
    "print(result[2].mean())\n",
    "print(result[2].std())\n",
    "print()\n",
    "\n",
    "print(\"EA_X:\", np.corrcoef(result[0], result[1]))\n",
    "print(\"Ea_lnR0:\", np.corrcoef(result[0], result[2]))\n",
    "print(\"X_lnR0:\", np.corrcoef(result[1], result[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kempe's function ported from excel\n",
    "# negative x values were causing errors when irr was small.\n",
    "@njit\n",
    "def forArrenius(poa_global, module_temp, ea, x, lnR0): # add type hinting\n",
    "    degredation = np.zeros_like(ea) # matches the number of samples in ea\n",
    "\n",
    "    # removing irradiance under 25 to avoid overflow errors, need to drop the corresponding index of module_temp\n",
    "    mask = poa_global >= 25\n",
    "\n",
    "    # drop elements\n",
    "    poa_global = poa_global[mask]\n",
    "    module_temp = module_temp[mask]\n",
    "    weather = len(poa_global) # length of updated array\n",
    "\n",
    "    # moved precalculations outside of loop, much faster this way\n",
    "    ea1 = ea / 8.31446261815324E-03\n",
    "    R0 = np.exp(lnR0)\n",
    "    poa_global_scaled = poa_global / 1000\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(weather):\n",
    "            # very inefficient, an element-wise approach would be siginficantly faster\n",
    "            degredation[i] += R0[i] * np.exp(-ea1[i] / (273.15 + module_temp[j])) * np.power(poa_global_scaled[j], x[i])\n",
    "            \n",
    "\n",
    "    return (degredation / 8760)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function testing ###\n",
    "# 8-13 seconds for 20K samples with numba\n",
    "\n",
    "# swapped to abs value of x\n",
    "# probably not right \n",
    "for_deg = forArrenius(poa_global=poa_irradiance['poa_global'].to_numpy(), module_temp=temp_mod.to_numpy(), ea=correlated_df['ea'].to_numpy(), x=correlated_df['x'].to_numpy(), lnR0=correlated_df['lnR0'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "0   5.696062e-04\n",
      "1   2.281007e-06\n",
      "2   4.923400e-06\n",
      "3   8.397144e-08\n",
      "4   9.375064e-04\n",
      "5   3.666189e+00\n",
      "6   9.133216e-05\n",
      "7   1.409482e-04\n",
      "8   1.856414e-04\n",
      "9   2.467306e-10\n",
      "10  7.170667e-05\n",
      "11  5.243333e-05\n",
      "12  8.942973e-06\n",
      "13  3.148846e-08\n",
      "14  3.334579e-06\n",
      "15  7.327797e-05\n",
      "16  1.178373e-08\n",
      "17  5.039729e-08\n",
      "18  1.339504e-04\n",
      "19  8.006623e-04\n",
      "0.0 % of rows have inf\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.DataFrame(for_deg)\n",
    "\n",
    "print(output_df.head(20))\n",
    "\n",
    "inf_values = output_df.isin([np.inf]).any(axis=1)\n",
    "num_rows_with_inf = inf_values.sum()\n",
    "print(num_rows_with_inf / n * 100, \"% of rows have inf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
